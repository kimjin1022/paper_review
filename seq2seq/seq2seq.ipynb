{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb014bba-767b-4550-a770-1a05b6aa9a9a",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c3337e-3723-4f98-8eef-75011691e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97e5144-1ed0-4790-bd16-58829c168c68",
   "metadata": {},
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e702bfb9-ae27-46fe-8e71-bf9e27f9e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "UNK_token = 3\n",
    "MAX_LENGTH = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57144744-e6fd-4a27-9110-c756cc471645",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2ed61f4-f17d-4a2f-9524-bbeb5dd70e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    text = re.sub(r'([^\\w\\s])', r' \\1 ', text)   \n",
    "    text = re.sub(r'\\s+', ' ', text) \n",
    "    text = text.strip()  \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c635e54f-0231-4eb1-8b13-cf666020e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(vocab, sentence):\n",
    "    return [vocab.get(word, vocab['<UNK>']) for word in sentence.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8ed3b3f-02a9-4a4c-8491-79cd4acd6759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorFromSentence(vocab, sentence):\n",
    "    indexes = indexesFromSentence(vocab, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d72c7f1a-f919-4e7c-b5fc-75f726ad7a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi, how are you doing?</td>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>i've been great. what about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>i've been good. i'm in school right now.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Question  \\\n",
       "0               hi, how are you doing?   \n",
       "1        i'm fine. how about yourself?   \n",
       "2  i'm pretty good. thanks for asking.   \n",
       "3    no problem. so how have you been?   \n",
       "4     i've been great. what about you?   \n",
       "\n",
       "                                     Answer  \n",
       "0             i'm fine. how about yourself?  \n",
       "1       i'm pretty good. thanks for asking.  \n",
       "2         no problem. so how have you been?  \n",
       "3          i've been great. what about you?  \n",
       "4  i've been good. i'm in school right now.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/chatbot_dataset.txt', sep='\\t', names=['Question', 'Answer'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be340288-457c-4450-8a0c-2969b0b3fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Encoder_Inputs'] = df['Question'].apply(clean_text)\n",
    "df['Decoder_Inputs'] = df['Answer'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aacd7bc5-7e04-435f-acea-e7ecd9be8b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Encoder_Inputs</th>\n",
       "      <th>Decoder_Inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi, how are you doing?</td>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>hi , how are you doing ?</td>\n",
       "      <td>i ' m fine . how about yourself ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>i ' m fine . how about yourself ?</td>\n",
       "      <td>i ' m pretty good . thanks for asking .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>i ' m pretty good . thanks for asking .</td>\n",
       "      <td>no problem . so how have you been ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>no problem . so how have you been ?</td>\n",
       "      <td>i ' ve been great . what about you ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>i've been good. i'm in school right now.</td>\n",
       "      <td>i ' ve been great . what about you ?</td>\n",
       "      <td>i ' ve been good . i ' m in school right now .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Question  \\\n",
       "0               hi, how are you doing?   \n",
       "1        i'm fine. how about yourself?   \n",
       "2  i'm pretty good. thanks for asking.   \n",
       "3    no problem. so how have you been?   \n",
       "4     i've been great. what about you?   \n",
       "\n",
       "                                     Answer  \\\n",
       "0             i'm fine. how about yourself?   \n",
       "1       i'm pretty good. thanks for asking.   \n",
       "2         no problem. so how have you been?   \n",
       "3          i've been great. what about you?   \n",
       "4  i've been good. i'm in school right now.   \n",
       "\n",
       "                            Encoder_Inputs  \\\n",
       "0                 hi , how are you doing ?   \n",
       "1        i ' m fine . how about yourself ?   \n",
       "2  i ' m pretty good . thanks for asking .   \n",
       "3      no problem . so how have you been ?   \n",
       "4     i ' ve been great . what about you ?   \n",
       "\n",
       "                                   Decoder_Inputs  \n",
       "0               i ' m fine . how about yourself ?  \n",
       "1         i ' m pretty good . thanks for asking .  \n",
       "2             no problem . so how have you been ?  \n",
       "3            i ' ve been great . what about you ?  \n",
       "4  i ' ve been good . i ' m in school right now .  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ff81b487-1a92-427c-846f-b7fd97e6a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = [sentence for sentence in df['Encoder_Inputs']]\n",
    "output_sentence = [sentence + \" <EOS>\" for sentence in df['Decoder_Inputs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7f60f720-bf74-4714-9ff6-885371e62988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi , how are you doing ?',\n",
       " \"i ' m fine . how about yourself ?\",\n",
       " \"i ' m pretty good . thanks for asking .\",\n",
       " 'no problem . so how have you been ?',\n",
       " \"i ' ve been great . what about you ?\"]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "95c3cfca-26d0-4d72-a372-44c1d0113cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"i ' m fine . how about yourself ? <EOS>\",\n",
       " \"i ' m pretty good . thanks for asking . <EOS>\",\n",
       " 'no problem . so how have you been ? <EOS>',\n",
       " \"i ' ve been great . what about you ? <EOS>\",\n",
       " \"i ' ve been good . i ' m in school right now . <EOS>\"]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentence[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3eafa739-575d-40bb-87fb-c6d9d7a2b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = set(\" \".join(df['Encoder_Inputs'].tolist() + df['Decoder_Inputs'].tolist()).split())\n",
    "vocab = {'<PAD>' : PAD_token, '<SOS>' : SOS_token, '<EOS>' : EOS_token, '<UNK>' : UNK_token}\n",
    "vocab.update({word : i+4 for i, word in enumerate(all_words)})\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1687d4c-f4ac-43e1-b83d-1ea728171be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataset/vocab.pkl', 'wb') as f:\n",
    "    pickle.dump(vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06bf347d-eab6-42de-ba15-ef70215501d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = vocab\n",
    "idx_to_word = {i : word for word, i in word_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bf1af3-5e9e-4203-bf3f-0114d8b23516",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db46ca31-e3a8-4786-92eb-f0ccce1a3f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=2)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(2, 1, self.hidden_size, device=device),\n",
    "                torch.zeros(2, 1, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4111d6f4-761e-460c-b876-e01c8096ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=2)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.out(output[0])\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(2, 1, self.hidden_size, device=device),\n",
    "                torch.zeros(2, 1, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "73fa77e1-9f14-4646-a047-ecc02631d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderLSTM(vocab_size, hidden_size).to(device)\n",
    "decoder = DecoderLSTM(hidden_size, vocab_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3efba022-a04e-4753-90af-2cbe1e4c8ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.005)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "473edb68-fc8d-4898-9088-804baa1c8747",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [list(x) for x in zip(df['Encoder_Inputs'], df['Decoder_Inputs'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d55e47d6-b0a9-4348-98c4-6e2c761cffbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi , how are you doing ?', \"i ' m fine . how about yourself ?\"]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dd7333e8-956f-49de-9e5b-e1a08e6cb687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:3.6210716095386357\n",
      "epoch:10, loss:3.425848677230278\n",
      "epoch:20, loss:2.88936164604236\n",
      "epoch:30, loss:2.1241015205164766\n",
      "epoch:40, loss:1.7065108936730204\n",
      "epoch:50, loss:1.337241018826608\n",
      "epoch:60, loss:1.2785630731401403\n",
      "epoch:70, loss:1.013029809638668\n",
      "epoch:80, loss:0.8444368172917225\n",
      "epoch:90, loss:0.7111186895707717\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "\n",
    "for i in range(epoch):\n",
    "    total_loss = 0\n",
    "\n",
    "    for idx in range(len(pairs)):\n",
    "        training_pair = pairs[idx]\n",
    "        input_tensor = tensorFromSentence(word_to_idx, training_pair[0]).to(device)\n",
    "        output_tensor = tensorFromSentence(word_to_idx, training_pair[1]).to(device)\n",
    "        \n",
    "        # 훈련\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        input_length = input_tensor.size(0)\n",
    "        output_length = output_tensor.size(0)\n",
    "\n",
    "        loss = 0\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        for di in range(output_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            loss += criterion(decoder_output, output_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() / output_length\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"epoch:{i}, loss:{total_loss / len(pairs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75e24fc-b355-4cd6-961b-b1f2c5932a1d",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "faf76bef-5d82-4497-9d43-7d4e5b306c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderLSTM(\n",
       "  (embedding): Embedding(433, 256)\n",
       "  (lstm): LSTM(256, 256, num_layers=2)\n",
       "  (out): Linear(in_features=256, out_features=433, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7cb523ad-2e48-4b56-95dd-a79bd88ca5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(word_to_idx, sentence).to(device)\n",
    "        input_length = input_tensor.size(0)\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_hidden = tuple([e.to(device) for e in encoder_hidden])\n",
    "        \n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        \n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = []  # output sentence\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                 decoded_words.append(idx_to_word[topi.item()])   #여기는 최종 아웃풋의 인덱스가 들어갑니다\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "        return ' '.join(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "39cd1b4b-717c-461d-a68b-f90236561266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채팅함수\n",
    "def chat(encoder, decoder, max_length=MAX_LENGTH):\n",
    "    print(\"Let's chat! (type 'bye' to exit)\")\n",
    "    while True:\n",
    "        input_sentence = input(\"> \")\n",
    "        if input_sentence == 'bye':\n",
    "            break\n",
    "        output_sentence = evaluate(encoder, decoder, input_sentence)\n",
    "        print('<', output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e7910ec9-651a-463b-87eb-63f1eda745d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's chat! (type 'bye' to exit)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  hi, how are you doing?\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< you were seen some just that that . . .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  how do you do?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< i you i see got . . . <EOS>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  bye\n"
     ]
    }
   ],
   "source": [
    "chat(encoder, decoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
